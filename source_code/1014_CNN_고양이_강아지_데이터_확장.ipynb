{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_img_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=180,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  zoom_range=0.3,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_img_gen.flow_from_directory(directory='../data/cats_and_dogs_filtered/train/',\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   batch_size=100,\n",
    "                                                   class_mode='binary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = data_img_gen.flow_from_directory(directory='../data/cats_and_dogs_filtered/validation/',\n",
    "                                                  target_size=(224, 224),\n",
    "                                                  batch_size=100,\n",
    "                                                  class_mode='binary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats/cat.0.jpg', 'cats/cat.1.jpg', 'cats/cat.10.jpg']\n",
      "['dogs/dog.997.jpg', 'dogs/dog.998.jpg', 'dogs/dog.999.jpg']\n",
      "데이터 개수:  2000\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.filenames[:3])\n",
    "print(train_generator.filenames[-3:])\n",
    "print('데이터 개수: ', len(train_generator.filenames))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats/cat.2000.jpg', 'cats/cat.2001.jpg', 'cats/cat.2002.jpg']\n",
      "['dogs/dog.2497.jpg', 'dogs/dog.2498.jpg', 'dogs/dog.2499.jpg']\n",
      "데이터 개수:  1000\n"
     ]
    }
   ],
   "source": [
    "print(test_generator.filenames[:3])\n",
    "print(test_generator.filenames[-3:])\n",
    "print('데이터 개수: ', len(test_generator.filenames))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN 모델 생성"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=(3, 3),\n",
    "                 activation='relu', padding='same',\n",
    "                 input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=(3, 3),\n",
    "                 activation='relu', padding='same'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-37e4b5f31456>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/3\n",
      "20/20 [==============================] - 67s 3s/step - loss: 1.5869 - accuracy: 0.5025 - val_loss: 0.6814 - val_accuracy: 0.5340\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 68s 3s/step - loss: 0.6775 - accuracy: 0.5530 - val_loss: 0.6753 - val_accuracy: 0.5800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.6631 - accuracy: 0.5975 - val_loss: 0.6591 - val_accuracy: 0.6050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1363d1e50>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=2000 // 100,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=1000 // 100,\n",
    "                    epochs=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 17s 2s/step - loss: 0.6568 - accuracy: 0.6180\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.6568478941917419, 0.6179999709129333]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model.save_weights('./model/cats_dogs.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## h5?\n",
    "\n",
    "* 나중에 모델을 재구성하기 위한 모델의 정보\n",
    "* 모델을 구성하는 각 뉴런들의 가중치\n",
    "* 재학습을 할 수 있도록 마지막 학습 상태"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-9dc0a8723efb>:1: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.46717924],\n       [0.43900084],\n       [0.6088009 ],\n       [0.4530367 ],\n       [0.53108364],\n       [0.6084822 ],\n       [0.44035244],\n       [0.6289575 ],\n       [0.5479112 ],\n       [0.5395971 ],\n       [0.6004939 ],\n       [0.40791506],\n       [0.45549577],\n       [0.44308487],\n       [0.64837426],\n       [0.43545216],\n       [0.25919005],\n       [0.54207265],\n       [0.4695656 ],\n       [0.5520712 ],\n       [0.7837554 ],\n       [0.44412094],\n       [0.52247554],\n       [0.58279526],\n       [0.72031724],\n       [0.5216299 ],\n       [0.50757414],\n       [0.5041738 ],\n       [0.46387923],\n       [0.5669053 ],\n       [0.4449665 ],\n       [0.6617586 ],\n       [0.4849278 ],\n       [0.5742715 ],\n       [0.31767458],\n       [0.48059684],\n       [0.49293464],\n       [0.7260212 ],\n       [0.7414002 ],\n       [0.5325466 ],\n       [0.4550805 ],\n       [0.3664128 ],\n       [0.50670385],\n       [0.3959318 ],\n       [0.90822065],\n       [0.5571166 ],\n       [0.4865543 ],\n       [0.6962287 ],\n       [0.5276981 ],\n       [0.42216125],\n       [0.67597663],\n       [0.54210055],\n       [0.64149845],\n       [0.5152386 ],\n       [0.45981053],\n       [0.62397826],\n       [0.06335139],\n       [0.644601  ],\n       [0.49322024],\n       [0.52964807],\n       [0.67652315],\n       [0.3430271 ],\n       [0.6553421 ],\n       [0.4216656 ],\n       [0.6901484 ],\n       [0.60638815],\n       [0.57018745],\n       [0.5973134 ],\n       [0.60811615],\n       [0.4442611 ],\n       [0.523057  ],\n       [0.3921344 ],\n       [0.8654978 ],\n       [0.4750368 ],\n       [0.56431365],\n       [0.61511636],\n       [0.47102925],\n       [0.5334474 ],\n       [0.4644478 ],\n       [0.44849434],\n       [0.15409201],\n       [0.49989086],\n       [0.5987866 ],\n       [0.6851117 ],\n       [0.5806734 ],\n       [0.43131286],\n       [0.43720782],\n       [0.7168319 ],\n       [0.47924405],\n       [0.38233802],\n       [0.43688166],\n       [0.472411  ],\n       [0.5520498 ],\n       [0.47604433],\n       [0.424251  ],\n       [0.5290144 ],\n       [0.4913428 ],\n       [0.47851595],\n       [0.58557236],\n       [0.8137696 ],\n       [0.7007485 ],\n       [0.44628853],\n       [0.4506007 ],\n       [0.45500633],\n       [0.47630915],\n       [0.5140556 ],\n       [0.42148447],\n       [0.45546895],\n       [0.36688665],\n       [0.57358116],\n       [0.38021523],\n       [0.59321827],\n       [0.48338473],\n       [0.4025795 ],\n       [0.4931208 ],\n       [0.67319286],\n       [0.45353344],\n       [0.43527013],\n       [0.41302428],\n       [0.72193676],\n       [0.4148028 ],\n       [0.70980173],\n       [0.4508029 ],\n       [0.52507293],\n       [0.43416178],\n       [0.7457973 ],\n       [0.5092274 ],\n       [0.43645263],\n       [0.29669434],\n       [0.0868988 ],\n       [0.61369956],\n       [0.5187436 ],\n       [0.61496013],\n       [0.459515  ],\n       [0.50860274],\n       [0.6253269 ],\n       [0.79710305],\n       [0.43927106],\n       [0.52537185],\n       [0.5888245 ],\n       [0.561491  ],\n       [0.51620734],\n       [0.7993336 ],\n       [0.4379002 ],\n       [0.48682204],\n       [0.78066707],\n       [0.51281583],\n       [0.64881283],\n       [0.46017215],\n       [0.5798093 ],\n       [0.39605772],\n       [0.5048766 ],\n       [0.4138098 ],\n       [0.4753607 ],\n       [0.7881091 ],\n       [0.5116709 ],\n       [0.5017724 ],\n       [0.6421044 ],\n       [0.1005629 ],\n       [0.4187586 ],\n       [0.29728842],\n       [0.5261644 ],\n       [0.56334   ],\n       [0.47741798],\n       [0.5644143 ],\n       [0.3979205 ],\n       [0.42600834],\n       [0.61589444],\n       [0.515986  ],\n       [0.48299485],\n       [0.37947595],\n       [0.5463304 ],\n       [0.7112535 ],\n       [0.47991967],\n       [0.44011655],\n       [0.61604095],\n       [0.5507981 ],\n       [0.53499174],\n       [0.41206402],\n       [0.6444514 ],\n       [0.5731144 ],\n       [0.5454199 ],\n       [0.41214707],\n       [0.6530026 ],\n       [0.55197257],\n       [0.37083986],\n       [0.67259866],\n       [0.60676104],\n       [0.69609565],\n       [0.3926483 ],\n       [0.39461556],\n       [0.55076617],\n       [0.550303  ],\n       [0.6836866 ],\n       [0.5386369 ],\n       [0.62925535],\n       [0.4359362 ],\n       [0.36025983],\n       [0.4183176 ],\n       [0.46456373],\n       [0.5621187 ],\n       [0.81393766],\n       [0.46002755],\n       [0.70796543],\n       [0.44075137],\n       [0.5616589 ],\n       [0.42052546],\n       [0.43516845],\n       [0.5257258 ],\n       [0.39963955],\n       [0.63369566],\n       [0.560191  ],\n       [0.39903978],\n       [0.4425555 ],\n       [0.7736591 ],\n       [0.32749814],\n       [0.72344965],\n       [0.4167804 ],\n       [0.57480943],\n       [0.554451  ],\n       [0.6900959 ],\n       [0.4395914 ],\n       [0.51673913],\n       [0.44227692],\n       [0.75148124],\n       [0.42167765],\n       [0.5243745 ],\n       [0.4801321 ],\n       [0.63947964],\n       [0.45380184],\n       [0.5172313 ],\n       [0.54179007],\n       [0.5014776 ],\n       [0.8364997 ],\n       [0.4733461 ],\n       [0.63355225],\n       [0.45885932],\n       [0.43661416],\n       [0.5588774 ],\n       [0.5550545 ],\n       [0.5622797 ],\n       [0.64906776],\n       [0.5817969 ],\n       [0.5249894 ],\n       [0.517538  ],\n       [0.510688  ],\n       [0.59138274],\n       [0.6907452 ],\n       [0.7700361 ],\n       [0.5255351 ],\n       [0.43863967],\n       [0.5663991 ],\n       [0.40948203],\n       [0.67528635],\n       [0.7342924 ],\n       [0.5254466 ],\n       [0.5619266 ],\n       [0.51135176],\n       [0.39472723],\n       [0.5012338 ],\n       [0.45715198],\n       [0.62499857],\n       [0.52341634],\n       [0.45664132],\n       [0.45216924],\n       [0.26973772],\n       [0.4635557 ],\n       [0.5959857 ],\n       [0.6624984 ],\n       [0.43053335],\n       [0.7988839 ],\n       [0.5053302 ],\n       [0.46005037],\n       [0.33975488],\n       [0.46309656],\n       [0.5783325 ],\n       [0.560431  ],\n       [0.4597067 ],\n       [0.46463582],\n       [0.3986292 ],\n       [0.45048562],\n       [0.43591318],\n       [0.27771774],\n       [0.4684025 ],\n       [0.4536729 ],\n       [0.42599148],\n       [0.3088894 ],\n       [0.65119874],\n       [0.58913565],\n       [0.40912506],\n       [0.39794326],\n       [0.8412247 ],\n       [0.41212568],\n       [0.43526354],\n       [0.43948868],\n       [0.46728018],\n       [0.4850643 ],\n       [0.62185377],\n       [0.5514447 ],\n       [0.4747032 ],\n       [0.4079455 ],\n       [0.5929748 ],\n       [0.401693  ],\n       [0.5445193 ],\n       [0.4689652 ],\n       [0.5827669 ],\n       [0.51124233],\n       [0.44517118],\n       [0.3995278 ],\n       [0.46052644],\n       [0.5576995 ],\n       [0.56688476],\n       [0.5015537 ],\n       [0.404387  ],\n       [0.4836477 ],\n       [0.62241745],\n       [0.40525872],\n       [0.47872636],\n       [0.4882928 ],\n       [0.4343921 ],\n       [0.5465456 ],\n       [0.49269426],\n       [0.45987648],\n       [0.57090366],\n       [0.64447105],\n       [0.38729858],\n       [0.66129726],\n       [0.4581915 ],\n       [0.47523448],\n       [0.86974573],\n       [0.4990818 ],\n       [0.8021894 ],\n       [0.63767433],\n       [0.3390499 ],\n       [0.5013983 ],\n       [0.5787039 ],\n       [0.51931   ],\n       [0.44987485],\n       [0.7388513 ],\n       [0.52964854],\n       [0.21114147],\n       [0.6131794 ],\n       [0.6277151 ],\n       [0.59610575],\n       [0.45934397],\n       [0.52508825],\n       [0.5555492 ],\n       [0.5281342 ],\n       [0.39903012],\n       [0.3778844 ],\n       [0.70210767],\n       [0.5465288 ],\n       [0.51856905],\n       [0.48765007],\n       [0.51343465],\n       [0.564862  ],\n       [0.48996747],\n       [0.49323785],\n       [0.44153643],\n       [0.5177663 ],\n       [0.7014823 ],\n       [0.6265228 ],\n       [0.46555772],\n       [0.4006289 ],\n       [0.4378411 ],\n       [0.47538853],\n       [0.4293263 ],\n       [0.6453439 ],\n       [0.60535944],\n       [0.5263224 ],\n       [0.5385103 ],\n       [0.43030873],\n       [0.5264419 ],\n       [0.5209074 ],\n       [0.49472675],\n       [0.44299912],\n       [0.45924595],\n       [0.714243  ],\n       [0.5982542 ],\n       [0.5565204 ],\n       [0.49539897],\n       [0.8356429 ],\n       [0.4961234 ],\n       [0.56036675],\n       [0.3746411 ],\n       [0.65983534],\n       [0.4889133 ],\n       [0.63093483],\n       [0.4850242 ],\n       [0.4587189 ],\n       [0.53142107],\n       [0.5249734 ],\n       [0.47685334],\n       [0.49501887],\n       [0.43242046],\n       [0.5599795 ],\n       [0.43280774],\n       [0.55288094],\n       [0.4247592 ],\n       [0.60216093],\n       [0.5120313 ],\n       [0.53639376],\n       [0.51756734],\n       [0.4523322 ],\n       [0.8121392 ],\n       [0.466116  ],\n       [0.47138166],\n       [0.59552467],\n       [0.7879243 ],\n       [0.4052819 ],\n       [0.531087  ],\n       [0.38308457],\n       [0.53898096],\n       [0.44898087],\n       [0.53225183],\n       [0.47624257],\n       [0.46586818],\n       [0.43900815],\n       [0.32142717],\n       [0.4777185 ],\n       [0.6486236 ],\n       [0.49238196],\n       [0.63967156],\n       [0.69939506],\n       [0.6647596 ],\n       [0.4130175 ],\n       [0.45867273],\n       [0.47748205],\n       [0.6159586 ],\n       [0.53858745],\n       [0.34351936],\n       [0.497788  ],\n       [0.44887432],\n       [0.46494958],\n       [0.61011374],\n       [0.4447954 ],\n       [0.64677113],\n       [0.5258663 ],\n       [0.41590574],\n       [0.46968645],\n       [0.41311038],\n       [0.35604227],\n       [0.6339463 ],\n       [0.5460204 ],\n       [0.43232226],\n       [0.5154469 ],\n       [0.60705453],\n       [0.41832402],\n       [0.530807  ],\n       [0.5466577 ],\n       [0.48416066],\n       [0.5233631 ],\n       [0.63238263],\n       [0.5108022 ],\n       [0.5187634 ],\n       [0.73834014],\n       [0.8010622 ],\n       [0.76097775],\n       [0.7566064 ],\n       [0.6672548 ],\n       [0.47584993],\n       [0.5226786 ],\n       [0.6592363 ],\n       [0.45240408],\n       [0.82348305],\n       [0.5857622 ],\n       [0.6833497 ],\n       [0.44928673],\n       [0.51856697],\n       [0.48657978],\n       [0.5014168 ],\n       [0.44652024],\n       [0.583215  ],\n       [0.45420983],\n       [0.4278203 ],\n       [0.44001842],\n       [0.3889454 ],\n       [0.7501556 ],\n       [0.8273401 ],\n       [0.54143775],\n       [0.3898992 ],\n       [0.6369779 ],\n       [0.49910998],\n       [0.4469945 ],\n       [0.46154234],\n       [0.4341607 ],\n       [0.55949473],\n       [0.8748572 ],\n       [0.51627564],\n       [0.6189415 ],\n       [0.5176841 ],\n       [0.5022697 ],\n       [0.4604258 ],\n       [0.6216399 ],\n       [0.5698048 ],\n       [0.44670495],\n       [0.65860975],\n       [0.93268526],\n       [0.76436484],\n       [0.58423865],\n       [0.48056048],\n       [0.44390738],\n       [0.46328422],\n       [0.52880996],\n       [0.6737987 ],\n       [0.54450035],\n       [0.39879674],\n       [0.57004756],\n       [0.5385775 ],\n       [0.57682383],\n       [0.38063496],\n       [0.5544792 ],\n       [0.5623399 ],\n       [0.60969055],\n       [0.45762268],\n       [0.4496601 ],\n       [0.47466877],\n       [0.6634366 ],\n       [0.7673352 ],\n       [0.638744  ],\n       [0.7144538 ],\n       [0.5529157 ],\n       [0.4168236 ],\n       [0.6955643 ],\n       [0.50503504],\n       [0.67391217],\n       [0.5689249 ],\n       [0.8488353 ],\n       [0.5686004 ],\n       [0.5449488 ],\n       [0.38881955],\n       [0.3737849 ],\n       [0.6129193 ],\n       [0.5825017 ],\n       [0.69555926],\n       [0.37059522],\n       [0.44622943],\n       [0.6396576 ],\n       [0.55785644],\n       [0.54954123],\n       [0.32588947],\n       [0.43634015],\n       [0.6079959 ],\n       [0.69519496],\n       [0.48533076],\n       [0.4513523 ],\n       [0.5847232 ],\n       [0.41455176],\n       [0.6133923 ],\n       [0.6005327 ],\n       [0.5117631 ],\n       [0.46766922],\n       [0.59867465],\n       [0.4337441 ],\n       [0.7295389 ],\n       [0.39187747],\n       [0.46277872],\n       [0.47619706],\n       [0.654835  ],\n       [0.6040287 ],\n       [0.50189126],\n       [0.44370756],\n       [0.79867524],\n       [0.4134343 ],\n       [0.56862754],\n       [0.39026028],\n       [0.54994994],\n       [0.53700566],\n       [0.51530737],\n       [0.54066014],\n       [0.43338466],\n       [0.50503093],\n       [0.5898573 ],\n       [0.38317096],\n       [0.46713537],\n       [0.5943286 ],\n       [0.6326098 ],\n       [0.3946432 ],\n       [0.6902862 ],\n       [0.42793983],\n       [0.7154216 ],\n       [0.64124   ],\n       [0.33794382],\n       [0.48495072],\n       [0.5215558 ],\n       [0.50566965],\n       [0.5995981 ],\n       [0.5553    ],\n       [0.5001004 ],\n       [0.31093988],\n       [0.6123951 ],\n       [0.59424484],\n       [0.40949273],\n       [0.64347064],\n       [0.41943055],\n       [0.5700222 ],\n       [0.59705395],\n       [0.29467827],\n       [0.51273537],\n       [0.52148366],\n       [0.43647808],\n       [0.6411217 ],\n       [0.8440391 ],\n       [0.6058324 ],\n       [0.43972275],\n       [0.47861326],\n       [0.5745594 ],\n       [0.6271174 ],\n       [0.47940612],\n       [0.5123885 ],\n       [0.4596275 ],\n       [0.40198386],\n       [0.89150095],\n       [0.48888   ],\n       [0.45420128],\n       [0.62969613],\n       [0.3766022 ],\n       [0.18844199],\n       [0.48143762],\n       [0.6951257 ],\n       [0.57326835],\n       [0.5079754 ],\n       [0.4204886 ],\n       [0.43722242],\n       [0.56640923],\n       [0.4147752 ],\n       [0.6498489 ],\n       [0.49377275],\n       [0.51325387],\n       [0.4671166 ],\n       [0.54410213],\n       [0.46628064],\n       [0.55910075],\n       [0.5649077 ],\n       [0.7152822 ],\n       [0.5951897 ],\n       [0.48638785],\n       [0.46784586],\n       [0.4584504 ],\n       [0.8173749 ],\n       [0.50855213],\n       [0.33115858],\n       [0.58385056],\n       [0.50685185],\n       [0.48558733],\n       [0.52501345],\n       [0.50458163],\n       [0.6543217 ],\n       [0.4295138 ],\n       [0.52388936],\n       [0.43659708],\n       [0.4561473 ],\n       [0.42457172],\n       [0.5981587 ],\n       [0.6085268 ],\n       [0.4492388 ],\n       [0.4822629 ],\n       [0.4641734 ],\n       [0.644811  ],\n       [0.819672  ],\n       [0.34032482],\n       [0.51637226],\n       [0.5804484 ],\n       [0.4018595 ],\n       [0.7352898 ],\n       [0.44200632],\n       [0.35707074],\n       [0.5667087 ],\n       [0.7149192 ],\n       [0.43146282],\n       [0.38956442],\n       [0.6259492 ],\n       [0.45572492],\n       [0.8487702 ],\n       [0.53602946],\n       [0.76719075],\n       [0.5646366 ],\n       [0.6354719 ],\n       [0.5408708 ],\n       [0.60915405],\n       [0.5279296 ],\n       [0.48574302],\n       [0.39214987],\n       [0.8009902 ],\n       [0.47149178],\n       [0.56781095],\n       [0.509063  ],\n       [0.62423676],\n       [0.2301302 ],\n       [0.8990394 ],\n       [0.45995736],\n       [0.42833298],\n       [0.04701325],\n       [0.4707448 ],\n       [0.4586219 ],\n       [0.54541045],\n       [0.7238219 ],\n       [0.47843206],\n       [0.4908772 ],\n       [0.28811163],\n       [0.45842814],\n       [0.5037551 ],\n       [0.5217903 ],\n       [0.43616688],\n       [0.6291307 ],\n       [0.7410017 ],\n       [0.5854184 ],\n       [0.5661786 ],\n       [0.65007794],\n       [0.46625292],\n       [0.71342444],\n       [0.52147   ],\n       [0.48195374],\n       [0.66118455],\n       [0.6088095 ],\n       [0.48131615],\n       [0.45077947],\n       [0.54025394],\n       [0.5331658 ],\n       [0.54730654],\n       [0.38554037],\n       [0.48715085],\n       [0.50266355],\n       [0.47068185],\n       [0.41446888],\n       [0.47131935],\n       [0.6225821 ],\n       [0.5203084 ],\n       [0.56119025],\n       [0.61255234],\n       [0.45314455],\n       [0.468862  ],\n       [0.47645506],\n       [0.45147386],\n       [0.82075584],\n       [0.71659297],\n       [0.46018228],\n       [0.5173714 ],\n       [0.4150539 ],\n       [0.4310373 ],\n       [0.42263007],\n       [0.57191056],\n       [0.4824355 ],\n       [0.5997145 ],\n       [0.44717792],\n       [0.47564432],\n       [0.5351038 ],\n       [0.8624146 ],\n       [0.62582135],\n       [0.38420227],\n       [0.68530685],\n       [0.3719442 ],\n       [0.5181122 ],\n       [0.54608595],\n       [0.47453454],\n       [0.4568203 ],\n       [0.55765754],\n       [0.6033655 ],\n       [0.70037305],\n       [0.44713762],\n       [0.7593831 ],\n       [0.60688627],\n       [0.47544944],\n       [0.54563653],\n       [0.4972225 ],\n       [0.55573833],\n       [0.62433106],\n       [0.3814198 ],\n       [0.54269814],\n       [0.7249739 ],\n       [0.6303852 ],\n       [0.5000929 ],\n       [0.42676473],\n       [0.48550028],\n       [0.521747  ],\n       [0.7185443 ],\n       [0.46805406],\n       [0.67628396],\n       [0.5289099 ],\n       [0.44417554],\n       [0.45364997],\n       [0.55461675],\n       [0.47870722],\n       [0.3517571 ],\n       [0.73210293],\n       [0.5836676 ],\n       [0.54393363],\n       [0.6406994 ],\n       [0.67092955],\n       [0.41457012],\n       [0.61848056],\n       [0.47044566],\n       [0.51854235],\n       [0.5181131 ],\n       [0.76681757],\n       [0.47102007],\n       [0.506503  ],\n       [0.6525334 ],\n       [0.6888907 ],\n       [0.6588691 ],\n       [0.5134024 ],\n       [0.5825508 ],\n       [0.73354   ],\n       [0.5307248 ],\n       [0.63953304],\n       [0.44383785],\n       [0.5193977 ],\n       [0.5009051 ],\n       [0.45108718],\n       [0.4371649 ],\n       [0.4714744 ],\n       [0.38629702],\n       [0.43462187],\n       [0.52001214],\n       [0.46283817],\n       [0.56306934],\n       [0.48676065],\n       [0.44582665],\n       [0.6999106 ],\n       [0.6254555 ],\n       [0.5590821 ],\n       [0.62737864],\n       [0.41721153],\n       [0.49498445],\n       [0.5630089 ],\n       [0.5144632 ],\n       [0.43001732],\n       [0.4564008 ],\n       [0.4252889 ],\n       [0.5884563 ],\n       [0.58480686],\n       [0.4911013 ],\n       [0.55534494],\n       [0.4910658 ],\n       [0.41428977],\n       [0.5606485 ],\n       [0.6286576 ],\n       [0.57295734],\n       [0.46708107],\n       [0.43695095],\n       [0.5108468 ],\n       [0.87779105],\n       [0.8195979 ],\n       [0.5033638 ],\n       [0.5006249 ],\n       [0.6126324 ],\n       [0.48819065],\n       [0.45677793],\n       [0.5603589 ],\n       [0.43371755],\n       [0.5055983 ],\n       [0.395249  ],\n       [0.6190454 ],\n       [0.611868  ],\n       [0.42793652],\n       [0.50084823],\n       [0.61227995],\n       [0.64827985],\n       [0.5583534 ],\n       [0.13193461],\n       [0.5236414 ],\n       [0.65951395],\n       [0.5655508 ],\n       [0.6358183 ],\n       [0.38590658],\n       [0.48584947],\n       [0.614884  ],\n       [0.7125536 ],\n       [0.51302207],\n       [0.54839605],\n       [0.5065323 ],\n       [0.45400745],\n       [0.54982245],\n       [0.51901734],\n       [0.53819054],\n       [0.6365739 ],\n       [0.5858681 ],\n       [0.545927  ],\n       [0.6154096 ],\n       [0.51661557],\n       [0.53853744],\n       [0.5621136 ],\n       [0.74711424],\n       [0.47607923],\n       [0.7674062 ],\n       [0.17754108],\n       [0.47564662],\n       [0.43077245],\n       [0.44668913],\n       [0.8474616 ],\n       [0.6253185 ],\n       [0.6048209 ],\n       [0.45653945],\n       [0.36745512],\n       [0.5972104 ],\n       [0.46280602],\n       [0.484141  ],\n       [0.5243709 ],\n       [0.46661574],\n       [0.49985737],\n       [0.5260039 ],\n       [0.46987575],\n       [0.501143  ],\n       [0.51328546],\n       [0.4354229 ],\n       [0.49414998],\n       [0.4558183 ],\n       [0.42083383],\n       [0.45543614],\n       [0.61256146],\n       [0.47993776],\n       [0.17801228],\n       [0.43389124],\n       [0.4699005 ],\n       [0.5276314 ],\n       [0.35885966],\n       [0.5475633 ],\n       [0.5026229 ],\n       [0.5205229 ],\n       [0.01411167],\n       [0.42219   ],\n       [0.44172528],\n       [0.43333894],\n       [0.49959108],\n       [0.43172187],\n       [0.36443776],\n       [0.6774589 ],\n       [0.5373453 ],\n       [0.51645565],\n       [0.5665804 ],\n       [0.5408133 ],\n       [0.62330866],\n       [0.54264235],\n       [0.52833146],\n       [0.62954694],\n       [0.67396027],\n       [0.54129016],\n       [0.53152966],\n       [0.35303748],\n       [0.6068888 ],\n       [0.45333534],\n       [0.57811874],\n       [0.45945105],\n       [0.5899902 ],\n       [0.7270565 ],\n       [0.33649492],\n       [0.4525067 ],\n       [0.8138111 ],\n       [0.4958046 ],\n       [0.4636039 ],\n       [0.406115  ],\n       [0.43432724],\n       [0.5264302 ],\n       [0.69392425],\n       [0.5689929 ],\n       [0.5122843 ],\n       [0.42272303],\n       [0.35726947],\n       [0.6201281 ],\n       [0.5969876 ],\n       [0.4887165 ],\n       [0.48535898],\n       [0.14461756],\n       [0.8534585 ],\n       [0.515206  ],\n       [0.43398798],\n       [0.7978349 ],\n       [0.46074384],\n       [0.4403856 ],\n       [0.7668556 ],\n       [0.46315372],\n       [0.4294833 ],\n       [0.45070305],\n       [0.43355078],\n       [0.4939252 ],\n       [0.55468065],\n       [0.68267626],\n       [0.49183974],\n       [0.4493038 ],\n       [0.4169219 ],\n       [0.63272434],\n       [0.63585174],\n       [0.2459828 ],\n       [0.6467536 ],\n       [0.6594252 ],\n       [0.39854035],\n       [0.4762892 ],\n       [0.708416  ],\n       [0.49301913],\n       [0.55675423],\n       [0.5290378 ],\n       [0.46595898],\n       [0.39431304],\n       [0.8510829 ],\n       [0.47585002],\n       [0.4512322 ],\n       [0.46470344],\n       [0.6924667 ],\n       [0.6008943 ],\n       [0.46658662]], dtype=float32)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_generator(test_generator, steps=1000//100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}